{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset (assuming it's in CSV format)\n",
        "file_path = '/content/neutrosophic_reviews.txt'\n",
        "\n",
        "# Parse the text file into a DataFrame\n",
        "reviews = []\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split(',')\n",
        "        review_id = int(parts[0])\n",
        "        truth = float(parts[1])\n",
        "        indeterminacy = float(parts[2])\n",
        "        falsity = float(parts[3])\n",
        "        reviews.append({\n",
        "            'id': review_id,\n",
        "            'truth': truth,\n",
        "            'indeterminacy': indeterminacy,\n",
        "            'falsity': falsity\n",
        "        })\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "reviews_df = pd.DataFrame(reviews)\n",
        "\n",
        "# Split the data into training and optimization sets\n",
        "train_data, optimization_data = train_test_split(reviews_df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Display the size of each dataset\n",
        "print(f'Training data size: {len(train_data)}')\n",
        "print(f'Optimization data size: {len(optimization_data)}')\n",
        "\n",
        "# Save the split datasets to CSV files (optional)\n",
        "train_data.to_csv('/content/train_data.csv', index=False)\n",
        "optimization_data.to_csv('/content/optimization_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "cjcm5ZjQMP1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m8b_H4-GFyRU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/amazon_uk_shoes_products_dataset_2021_12.csv'\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nvKbRHEWF85h",
        "outputId": "c0781458-d4c1-4eea-d538-4c6e72713c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      url  \\\n",
            "0  https://www.amazon.co.uk/dp/B07SBX32T5   \n",
            "1  https://www.amazon.co.uk/dp/B07SBX32T5   \n",
            "2  https://www.amazon.co.uk/dp/B07SBX32T5   \n",
            "3  https://www.amazon.co.uk/dp/B07SBX32T5   \n",
            "4  https://www.amazon.co.uk/dp/B08SW434MG   \n",
            "\n",
            "                                        product_name     reviewer_name  \\\n",
            "0  Klasified Women's Transparent Clear Sneaker Sh...  Jocelyn McSayles   \n",
            "1  Klasified Women's Transparent Clear Sneaker Sh...      Kenia Rivera   \n",
            "2  Klasified Women's Transparent Clear Sneaker Sh...       Chris Souza   \n",
            "3  Klasified Women's Transparent Clear Sneaker Sh...   Amazon Customer   \n",
            "4  GUESS Women's Bradly Gymnastics Shoe, White, 7 UK         Graziella   \n",
            "\n",
            "         review_title                                        review_text  \\\n",
            "0             Love em  Love these. Was looking for converses and thes...   \n",
            "1  The plastic ripped  The shoes are very cute, but after the 2nd day...   \n",
            "2        Good quality                                       Good quality   \n",
            "3                Good                                              Great   \n",
            "4          PERFETTE!!  Ho scelto il modello bianco con rifinitura die...   \n",
            "\n",
            "   review_rating  verified_purchase  \\\n",
            "0            5.0               True   \n",
            "1            2.0               True   \n",
            "2            5.0               True   \n",
            "3            5.0               True   \n",
            "4            5.0               True   \n",
            "\n",
            "                                        review_date  \\\n",
            "0      Reviewed in the United States on 2 June 2020   \n",
            "1  Reviewed in the United States on 28 October 2021   \n",
            "2  Reviewed in the United States on 20 January 2021   \n",
            "3    Reviewed in the United States on 22 April 2021   \n",
            "4                 Reviewed in Italy on 2 April 2021   \n",
            "\n",
            "                 helpful_count                               uniq_id  \\\n",
            "0  2 people found this helpful  36eae4e5-2894-5279-a0b7-d2b330e2b814   \n",
            "1                          NaN  f4778bb8-3070-5cb1-b5aa-ffce41a97b57   \n",
            "2                          NaN  db5a7525-d40b-5265-84d8-df4f29837a3b   \n",
            "3                          NaN  75a42851-6462-54b5-988a-27d336221943   \n",
            "4  2 people found this helpful  232dee43-849e-5d06-ba05-efb3f4814714   \n",
            "\n",
            "            scraped_at  \n",
            "0  24/12/2021 02:26:25  \n",
            "1  24/12/2021 02:26:25  \n",
            "2  24/12/2021 02:26:25  \n",
            "3  24/12/2021 02:26:25  \n",
            "4  24/12/2021 02:26:25  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6823 entries, 0 to 6822\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   url                6823 non-null   object \n",
            " 1   product_name       6823 non-null   object \n",
            " 2   reviewer_name      6823 non-null   object \n",
            " 3   review_title       6822 non-null   object \n",
            " 4   review_text        6814 non-null   object \n",
            " 5   review_rating      6823 non-null   float64\n",
            " 6   verified_purchase  6823 non-null   bool   \n",
            " 7   review_date        6823 non-null   object \n",
            " 8   helpful_count      1953 non-null   object \n",
            " 9   uniq_id            6823 non-null   object \n",
            " 10  scraped_at         6823 non-null   object \n",
            "dtypes: bool(1), float64(1), object(9)\n",
            "memory usage: 539.8+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(data.head())\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WVyFZb9cF_EE"
      },
      "outputs": [],
      "source": [
        "columns = ['product_name', 'reviewer_name', 'review_title', 'review_text', 'review_rating',\n",
        "           'verified_purchase', 'review_date', 'helpful_count', 'uniq_id']\n",
        "data = data[columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wrUVIt93GRC4"
      },
      "outputs": [],
      "source": [
        "# Remove rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "# Handle missing values\n",
        "data['review_title'].fillna('No Title', inplace=True)\n",
        "data['review_text'].fillna('No Review', inplace=True)\n",
        "data['helpful_count'].fillna('0 people found this helpful', inplace=True)\n",
        "data.dropna(subset=['review_text', 'review_rating'], inplace=True)\n",
        "data.drop_duplicates(subset=['uniq_id'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_date(review_date):\n",
        "    match = re.search(r'on (\\\\d{1,2} \\\\w+ \\\\d{4})', review_date)\n",
        "    if match:\n",
        "        return pd.to_datetime(match.group(1), format='%d %B %Y')\n",
        "    return None\n",
        "\n",
        "data['parsed_date'] = data['review_date'].apply(extract_date)"
      ],
      "metadata": {
        "id": "_27DAhVXFEXO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(subset=['review_text', 'review_rating'], inplace=True)\n",
        "data.drop_duplicates(subset=['uniq_id'], inplace=True)"
      ],
      "metadata": {
        "id": "Mqe99mOrFKyq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBOHC5xrG0Ts",
        "outputId": "d5bb5aa0-46f1-4b78-dc7b-6a07114b6fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No duplicates found in the file.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "input_file = '/content/amazon_uk_shoes_products_dataset_2021_12.csv'\n",
        "\n",
        "def read_csv(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            yield row\n",
        "\n",
        "def make_hashable(item):\n",
        "    if isinstance(item, dict):\n",
        "        return tuple((k, make_hashable(v)) for k, v in item.items())\n",
        "    elif isinstance(item, list):\n",
        "        return tuple(make_hashable(i) for i in item)\n",
        "    else:\n",
        "        return item\n",
        "\n",
        "seen = set()\n",
        "duplicates = []\n",
        "\n",
        "for item in read_csv(input_file):\n",
        "    item_tuple = make_hashable(item)\n",
        "    if item_tuple in seen:\n",
        "        duplicates.append(item)\n",
        "    else:\n",
        "        seen.add(item_tuple)\n",
        "\n",
        "if duplicates:\n",
        "    print(f\"Found {len(duplicates)} duplicates in the file.\")\n",
        "else:\n",
        "    print(\"No duplicates found in the file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with NaN values in 'review_text'\n",
        "data = data.dropna(subset=['review_text'])\n",
        "\n",
        "# Then proceed with TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "tfidf_matrix = vectorizer.fit_transform(data['review_text'])\n",
        "# Fill NaN values with an empty string or other placeholder text\n",
        "data['review_text'].fillna('', inplace=True)\n",
        "\n",
        "# Then proceed with TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "tfidf_matrix = vectorizer.fit_transform(data['review_text'])\n"
      ],
      "metadata": {
        "id": "UQEAiYmSGWaR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode review text using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "tfidf_matrix = vectorizer.fit_transform(data['review_text'])"
      ],
      "metadata": {
        "id": "BHox3U4WFdz2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create additional features\n",
        "data['review_length'] = data['review_text'].apply(len)"
      ],
      "metadata": {
        "id": "KfRDBrFOFkNN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your cleaned DataFrame\n",
        "# Replace 'cleaned_data.csv' with your desired file name and path\n",
        "file_path = 'cleaned_data.csv'\n",
        "\n",
        "# Save DataFrame to CSV file\n",
        "data.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"Cleaned dataset saved to {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc3uang_MGoq",
        "outputId": "7bc5b1e2-b663-4293-fd99-1b86551fe45c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset saved to cleaned_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic information about the cleaned dataset\n",
        "data_info_cleaned = data.info()\n",
        "data_head_cleaned = data.head()\n",
        "\n",
        "data_info_cleaned, data_head_cleaned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbg0rOToeAvi",
        "outputId": "212f2340-c696-47e1-9ff2-22912c322abf",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1890 entries, 0 to 6816\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   product_name       1890 non-null   object \n",
            " 1   reviewer_name      1890 non-null   object \n",
            " 2   review_title       1890 non-null   object \n",
            " 3   review_text        1890 non-null   object \n",
            " 4   review_rating      1890 non-null   float64\n",
            " 5   verified_purchase  1890 non-null   bool   \n",
            " 6   review_date        1890 non-null   object \n",
            " 7   helpful_count      1890 non-null   object \n",
            " 8   uniq_id            1890 non-null   object \n",
            " 9   parsed_date        0 non-null      object \n",
            " 10  review_length      1890 non-null   int64  \n",
            "dtypes: bool(1), float64(1), int64(1), object(8)\n",
            "memory usage: 164.3+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "                                          product_name     reviewer_name  \\\n",
              " 0   Klasified Women's Transparent Clear Sneaker Sh...  Jocelyn McSayles   \n",
              " 4   GUESS Women's Bradly Gymnastics Shoe, White, 7 UK         Graziella   \n",
              " 6   GUESS Women's Bradly Gymnastics Shoe, White, 7 UK           Cliente   \n",
              " 14  adidas Women's Retrorun Shoes Running, Core Bl...           Lindsay   \n",
              " 17     Aravon Women's Betty-AR Oxfords, Stone, 5.5 UK   Amazon Customer   \n",
              " \n",
              "                    review_title  \\\n",
              " 0                       Love em   \n",
              " 4                    PERFETTE!!   \n",
              " 6                   Molto belle   \n",
              " 14  Perfect right outta the box   \n",
              " 17   Comfortable and attractive   \n",
              " \n",
              "                                           review_text  review_rating  \\\n",
              " 0   Love these. Was looking for converses and thes...            5.0   \n",
              " 4   Ho scelto il modello bianco con rifinitura die...            5.0   \n",
              " 6   Le scarpe sono molto belle, calzano perfettamente            5.0   \n",
              " 14  True to size. If between I'd probably go with ...            5.0   \n",
              " 17  I have hard to fit feet and often a wide fitti...            5.0   \n",
              " \n",
              "     verified_purchase                                   review_date  \\\n",
              " 0                True  Reviewed in the United States on 2 June 2020   \n",
              " 4                True             Reviewed in Italy on 2 April 2021   \n",
              " 6                True             Reviewed in Italy on 8 April 2021   \n",
              " 14               True         Reviewed in Canada on 20 October 2021   \n",
              " 17               True          Reviewed in Canada on 8 October 2018   \n",
              " \n",
              "                     helpful_count                               uniq_id  \\\n",
              " 0     2 people found this helpful  36eae4e5-2894-5279-a0b7-d2b330e2b814   \n",
              " 4     2 people found this helpful  232dee43-849e-5d06-ba05-efb3f4814714   \n",
              " 6     2 people found this helpful  deb5e278-70b5-5e2c-9ad7-93bf5c26a41d   \n",
              " 14  One person found this helpful  b64632c5-6f24-51eb-9275-6614fed29f1a   \n",
              " 17    2 people found this helpful  bce0114a-c0fe-5472-bbb8-377cb21dc853   \n",
              " \n",
              "    parsed_date  review_length  \n",
              " 0         None            211  \n",
              " 4         None            312  \n",
              " 6         None             49  \n",
              " 14        None            322  \n",
              " 17        None            360  )"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a_stQHjtKvE"
      },
      "source": [
        "Now Convert the user-generated content into neutrosophic sets. Each review will be represented as a triplet T(I,F,N) where:\n",
        "T is the degree of truth (positive feedback).\n",
        "I is the degree of indeterminacy (neutral or ambiguous feedback).\n",
        "F is the degree of falsity (negative feedback)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P2kpOEPcAPWg",
        "outputId": "fae05dac-9081-4f57-cf3a-f2788f44cda2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutrosophic reviews have been written to: /content/neutrosophic_reviews.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Function to classify review text and rating into neutrosophic sets with sentiment analysis\n",
        "def classify_review_rating(review_text, review_rating):\n",
        "    review_rating = float(review_rating)\n",
        "\n",
        "    # Ensure review_text is a string\n",
        "    review_text = str(review_text)\n",
        "\n",
        "    # Perform sentiment analysis on review text\n",
        "    sentiment = TextBlob(review_text).sentiment\n",
        "    polarity = sentiment.polarity\n",
        "\n",
        "    # Define thresholds for sentiment polarity\n",
        "    positive_threshold = 0.1\n",
        "    negative_threshold = -0.1\n",
        "\n",
        "    # Define membership functions for truth (T), indeterminacy (I), and falsity (F)\n",
        "    if review_rating >= 4 and polarity > positive_threshold:\n",
        "        return (1.0, 0.0, 0.0)  # High truth, low indeterminacy, low falsity\n",
        "    elif review_rating <= 2 and polarity < negative_threshold:\n",
        "        return (0.0, 0.0, 1.0)  # Low truth, low indeterminacy, high falsity\n",
        "    elif review_rating == 3 or (polarity >= -0.3 and polarity <= 0.3):\n",
        "        return (0.0, 1.0, 0.0)  # Low truth, high indeterminacy, low falsity\n",
        "    else:\n",
        "        return (0.5, 0.5, 0.0)  # Moderate truth, moderate indeterminacy, low falsity\n",
        "\n",
        "# Load your dataset (assuming 'data' is your DataFrame)\n",
        "data = pd.read_csv('/content/amazon_uk_shoes_products_dataset_2021_12.csv')\n",
        "\n",
        "# Apply the classification function with sentiment analysis to each review\n",
        "data[['truth', 'indeterminacy', 'falsity']] = data.apply(\n",
        "    lambda row: pd.Series(classify_review_rating(row['review_text'], row['review_rating'])), axis=1)\n",
        "\n",
        "# Handle contradictory information\n",
        "def handle_contradictions(truth, indeterminacy, falsity):\n",
        "    # Example rule: If both truth and falsity are high, adjust indeterminacy\n",
        "    if truth > 0.5 and falsity > 0.5:\n",
        "        indeterminacy = max(indeterminacy, 0.5)\n",
        "    return truth, indeterminacy, falsity\n",
        "\n",
        "data[['truth', 'indeterminacy', 'falsity']] = data.apply(\n",
        "    lambda row: pd.Series(handle_contradictions(row['truth'], row['indeterminacy'], row['falsity'])), axis=1)\n",
        "\n",
        "# Quantify uncertainty (if needed)\n",
        "def quantify_uncertainty(review_text, review_rating):\n",
        "    # Define thresholds and probabilistic approaches here if needed\n",
        "    uncertainty_score = np.random.uniform(0.1, 0.9)\n",
        "    return uncertainty_score\n",
        "\n",
        "data['uncertainty'] = data.apply(lambda row: quantify_uncertainty(row['review_text'], row['review_rating']), axis=1)\n",
        "\n",
        "# Define thresholds for classification\n",
        "positive_threshold = 0.6\n",
        "negative_threshold = 0.4\n",
        "\n",
        "# Function to classify reviews\n",
        "def classify_reviews(truth, indeterminacy, falsity):\n",
        "    if truth >= positive_threshold:\n",
        "        return 'Positive'\n",
        "    elif falsity >= negative_threshold:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply classification function to each review\n",
        "data['review_sentiment'] = data.apply(lambda row: classify_reviews(row['truth'], row['indeterminacy'], row['falsity']), axis=1)\n",
        "\n",
        "# Define the output file path as CSV\n",
        "output_file_path = '/content/neutrosophic_reviews.csv'\n",
        "\n",
        "# Write reviews and neutrosophic values to the output CSV file\n",
        "data.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Neutrosophic reviews have been written to:\", output_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3WmGOvA09y"
      },
      "source": [
        "total count of positive, negative and neutral reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7B_tHFY_kh0",
        "outputId": "665b14e9-e337-4436-c553-94decc892eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Reviews: 2870\n",
            "Negative Reviews: 177\n",
            "Neutral Reviews: 3776\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'data' is your DataFrame containing neutrosophic reviews\n",
        "\n",
        "# Define thresholds for classification\n",
        "positive_threshold = 0.6  # Adjust as needed based on your neutrosophic logic framework\n",
        "negative_threshold = 0.4  # Adjust as needed based on your neutrosophic logic framework\n",
        "\n",
        "# Function to classify reviews\n",
        "def classify_reviews(truth, indeterminacy, falsity):\n",
        "    if truth >= positive_threshold:\n",
        "        return 'Positive'\n",
        "    elif falsity >= negative_threshold:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply classification function to each review\n",
        "data['review_sentiment'] = data.apply(lambda row: classify_reviews(row['truth'], row['indeterminacy'], row['falsity']), axis=1)\n",
        "\n",
        "# Count positive, negative, and neutral reviews\n",
        "positive_count = data[data['review_sentiment'] == 'Positive'].shape[0]\n",
        "negative_count = data[data['review_sentiment'] == 'Negative'].shape[0]\n",
        "neutral_count = data[data['review_sentiment'] == 'Neutral'].shape[0]\n",
        "\n",
        "print(f\"Positive Reviews: {positive_count}\")\n",
        "print(f\"Negative Reviews: {negative_count}\")\n",
        "print(f\"Neutral Reviews: {neutral_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ePee9iCAvxI"
      },
      "source": [
        "count of positive, negative, neutral reviews by product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9_Bu49Su_kZf",
        "outputId": "2975aca6-af08-467c-dda8-5906add8019f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of Positive, Negative, and Neutral Reviews by Product:\n",
            "review_sentiment                                    Negative  Neutral  \\\n",
            "product_name                                                            \n",
            "': 'ZAPATILLA NEW BALANCE KV220, Navy/White, 9....         2        4   \n",
            "ACE Constructor High S3 Work Boots - Mens Leath...         0       10   \n",
            "ALLY UNION MAKE FORCE Mens Womens Walking Shoes...         1        2   \n",
            "ANNE KLEIN Women's Anne Kleon Onthego Sneaker, ...         0        0   \n",
            "ANNE KLEIN Women's Terri Sneaker, Grey Heathere...         1        5   \n",
            "...                                                      ...      ...   \n",
            "victoria Unisex 106500-women Hi-Top Trainers, W...         0        9   \n",
            "victoria Unisex Adults JUEGOS Slip ON LONA Mult...         0        1   \n",
            "victoria Unisex Deportivo Laser Estrellas Train...         0        4   \n",
            "victoria Unisex Kids Deportivo Lurex Trainers, ...         1        5   \n",
            "victoria Women's Basket Terciopelo Trainers, Gr...         0        1   \n",
            "\n",
            "review_sentiment                                    Positive  \n",
            "product_name                                                  \n",
            "': 'ZAPATILLA NEW BALANCE KV220, Navy/White, 9....         4  \n",
            "ACE Constructor High S3 Work Boots - Mens Leath...         0  \n",
            "ALLY UNION MAKE FORCE Mens Womens Walking Shoes...         7  \n",
            "ANNE KLEIN Women's Anne Kleon Onthego Sneaker, ...         1  \n",
            "ANNE KLEIN Women's Terri Sneaker, Grey Heathere...         4  \n",
            "...                                                      ...  \n",
            "victoria Unisex 106500-women Hi-Top Trainers, W...         1  \n",
            "victoria Unisex Adults JUEGOS Slip ON LONA Mult...         1  \n",
            "victoria Unisex Deportivo Laser Estrellas Train...         1  \n",
            "victoria Unisex Kids Deportivo Lurex Trainers, ...         0  \n",
            "victoria Women's Basket Terciopelo Trainers, Gr...         0  \n",
            "\n",
            "[1086 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'data' is your DataFrame containing neutrosophic reviews\n",
        "\n",
        "# Group by product and count positive, negative, and neutral reviews\n",
        "product_sentiment_counts = data.groupby('product_name')['review_sentiment'].value_counts().unstack(fill_value=0)\n",
        "\n",
        "# Display the counts\n",
        "print(\"Count of Positive, Negative, and Neutral Reviews by Product:\")\n",
        "print(product_sentiment_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kttBqPdA1sg_"
      },
      "source": [
        "Aggregation Using Neutrosophic Logic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_neutrosophic_sets(reviews):\n",
        "    # Placeholder function to demonstrate structure\n",
        "    # Assuming 'reviews' is a DataFrame with columns 'truth', 'indeterminacy', 'falsity'\n",
        "\n",
        "    total_truth = reviews['truth'].mean()\n",
        "    total_indeterminacy = reviews['indeterminacy'].mean()\n",
        "    total_falsity = reviews['falsity'].mean()\n",
        "\n",
        "    return pd.Series({'Aggregated Truth': total_truth, 'Aggregated Indeterminacy': total_indeterminacy, 'Aggregated Falsity': total_falsity})\n"
      ],
      "metadata": {
        "id": "De42yGzAsZY6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1eT9si-DsCU",
        "outputId": "0d09cdb2-5172-4528-91b6-aa2a403591ba",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated neutrosophic reviews have been written to: aggregated_neutrosophic_reviews.csv\n"
          ]
        }
      ],
      "source": [
        "def aggregate_neutrosophic_sets(group):\n",
        "    # Calculate the mean of truth, indeterminacy, and falsity for the group\n",
        "    aggregated_truth = group['truth'].mean()\n",
        "    aggregated_indeterminacy = group['indeterminacy'].mean()\n",
        "    aggregated_falsity = group['falsity'].mean()\n",
        "\n",
        "    # Return a Series with the aggregated values\n",
        "    return pd.Series({\n",
        "        'Aggregated Truth': aggregated_truth,\n",
        "        'Aggregated Indeterminacy': aggregated_indeterminacy,\n",
        "        'Aggregated Falsity': aggregated_falsity\n",
        "    })\n",
        "\n",
        "# Apply the aggregation for each product or vendor\n",
        "product_aggregates = data.groupby('product_name').apply(aggregate_neutrosophic_sets).reset_index()\n",
        "\n",
        "# Save the aggregated results\n",
        "output_aggregate_path = 'aggregated_neutrosophic_reviews.csv'\n",
        "product_aggregates.to_csv(output_aggregate_path, index=False)\n",
        "print(\"Aggregated neutrosophic reviews have been written to:\", output_aggregate_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj9l1stv4LbA",
        "collapsed": true,
        "outputId": "26904f94-f2e0-4340-c74e-13491505aa0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated Truth: 0.42657188919829986\n",
            "Aggregated Indeterminacy: 0.5474864429136743\n",
            "Aggregated Falsity: 0.025941667888025793\n"
          ]
        }
      ],
      "source": [
        "# Aggregate neutrosophic sets for the entire dataset\n",
        "total_truth = data['truth'].mean()\n",
        "total_indeterminacy = data['indeterminacy'].mean()\n",
        "total_falsity = data['falsity'].mean()\n",
        "\n",
        "# Output the aggregated results\n",
        "print(f\"Aggregated Truth: {total_truth}\")\n",
        "print(f\"Aggregated Indeterminacy: {total_indeterminacy}\")\n",
        "print(f\"Aggregated Falsity: {total_falsity}\")\n",
        "\n",
        "\n",
        "# Save the aggregated results to a CSV file\n",
        "aggregate_results = pd.DataFrame({\n",
        "    'Aggregated Truth': [total_truth],\n",
        "    'Aggregated Indeterminacy': [total_indeterminacy],\n",
        "    'Aggregated Falsity': [total_falsity]\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rctOyTo8EvlO"
      },
      "source": [
        "pso optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyswarm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66BAkr0VtE2",
        "outputId": "d7393aef-2e17-424e-dce1-4442dcb537ef"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarm\n",
            "  Downloading pyswarm-0.6.tar.gz (4.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarm) (1.25.2)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-py3-none-any.whl size=4464 sha256=4f798a65e267162378de447bb601acf44a20676f88dadfdd15348cfa919d3427\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/67/40/62fa158f497f942277cbab8199b05cb61c571ab324e67ad0d6\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from pyswarm import pso\n",
        "\n",
        "# Load the aggregated neutrosophic reviews dataset\n",
        "aggregated_reviews_df = pd.read_csv('/content/aggregated_neutrosophic_reviews.csv')\n",
        "\n",
        "# Prepare the reviews\n",
        "reviews = []\n",
        "for index, row in aggregated_reviews_df.iterrows():\n",
        "    reviews.append({\n",
        "        'id': index,\n",
        "        'truth': row['Aggregated Truth'],\n",
        "        'indeterminacy': row['Aggregated Indeterminacy'],\n",
        "        'falsity': row['Aggregated Falsity']\n",
        "    })\n",
        "\n",
        "# Define the customized objective function for PSO\n",
        "def objective_function(solution, reviews):\n",
        "    total_error = 0\n",
        "    weights = [0.6, 0.2, 0.2]  # Custom weights for T, I, F, emphasizing T\n",
        "    penalty = 0.1  # Penalty factor for indeterminacy (I)\n",
        "\n",
        "    for review in reviews:\n",
        "        truth_error = abs(review['truth'] - solution[0])\n",
        "        indeterminacy_error = abs(review['indeterminacy'] - solution[1])\n",
        "        falsity_error = abs(review['falsity'] - solution[2])\n",
        "\n",
        "        total_error += (weights[0] * truth_error +\n",
        "                        weights[1] * indeterminacy_error +\n",
        "                        weights[2] * falsity_error +\n",
        "                        penalty * review['indeterminacy'])\n",
        "\n",
        "    return total_error\n",
        "\n",
        "# PSO parameters\n",
        "num_particles = 50  # Number of particles for better search diversity\n",
        "num_iterations = 150  # More iterations for better optimization\n",
        "w = 0.7  # Inertia weight\n",
        "c1 = 1.5  # Cognitive parameter\n",
        "c2 = 1.5  # Social parameter\n",
        "\n",
        "# Initialize particles and velocities\n",
        "particles = [np.random.rand(3) for _ in range(num_particles)]\n",
        "velocities = [np.random.rand(3) for _ in range(num_particles)]\n",
        "personal_best_positions = particles.copy()\n",
        "personal_best_scores = [objective_function(p, reviews) for p in particles]\n",
        "global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n",
        "\n",
        "# PSO algorithm\n",
        "for _ in range(num_iterations):\n",
        "    for i, particle in enumerate(particles):\n",
        "        # Update velocity\n",
        "        r1, r2 = random.random(), random.random()\n",
        "        velocities[i] = (w * velocities[i] +\n",
        "                         c1 * r1 * (personal_best_positions[i] - particle) +\n",
        "                         c2 * r2 * (global_best_position - particle))\n",
        "\n",
        "        # Update position\n",
        "        particles[i] = particles[i] + velocities[i]\n",
        "\n",
        "        # Ensure particles stay within bounds [0, 1]\n",
        "        particles[i] = np.clip(particles[i], 0, 1)\n",
        "\n",
        "        # Evaluate new position\n",
        "        current_score = objective_function(particles[i], reviews)\n",
        "        if current_score < personal_best_scores[i]:  # Minimizing error\n",
        "            personal_best_positions[i] = particles[i]\n",
        "            personal_best_scores[i] = current_score\n",
        "\n",
        "        # Update global best position\n",
        "        if current_score < min(personal_best_scores):\n",
        "            global_best_position = particles[i]\n",
        "\n",
        "print(\"Optimized Aggregation Method:\", global_best_position)\n",
        "\n",
        "# Apply the optimal weights to evaluate the reviews\n",
        "optimized_reviews = []\n",
        "for review in reviews:\n",
        "    weighted_sum = (global_best_position[0] * review['truth'] +\n",
        "                    global_best_position[1] * review['indeterminacy'] +\n",
        "                    global_best_position[2] * review['falsity'])\n",
        "\n",
        "    optimized_review = review.copy()\n",
        "    optimized_review['weighted_sum'] = weighted_sum\n",
        "    optimized_reviews.append(optimized_review)\n",
        "\n",
        "# Convert to DataFrame for further analysis\n",
        "optimized_reviews_df = pd.DataFrame(optimized_reviews)\n",
        "print(optimized_reviews_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIPxKUPT_gmu",
        "outputId": "4fe4c10b-23f1-43e3-a8dd-57a7307dc456"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Aggregation Method: [0.22053602 0.57753986 0.01154213]\n",
            "        id  truth  indeterminacy   falsity  weighted_sum\n",
            "0        0   0.40       0.400000  0.200000      0.321539\n",
            "1        1   0.00       1.000000  0.000000      0.577540\n",
            "2        2   0.75       0.150000  0.100000      0.253187\n",
            "3        3   1.00       0.000000  0.000000      0.220536\n",
            "4        4   0.40       0.500000  0.100000      0.378139\n",
            "...    ...    ...            ...       ...           ...\n",
            "1081  1081   0.10       0.900000  0.000000      0.541839\n",
            "1082  1082   0.50       0.500000  0.000000      0.399038\n",
            "1083  1083   0.20       0.800000  0.000000      0.506139\n",
            "1084  1084   0.00       0.833333  0.166667      0.483207\n",
            "1085  1085   0.00       1.000000  0.000000      0.577540\n",
            "\n",
            "[1086 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PbaHVERTKUF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}